# Best practices in programming {#sec-r-programming}

## Code Organisation

### Modular Programming

**Importance of modularity**  
Breaking down your code into functions and modules enhances readability, maintainability, and reusability. This approach helps isolate specific tasks and allows for easier debugging and testing.

::: {.callout-note}
#### Single-responsability Principle {.unnumbered} 

The Single-responsibility Principle (SRP) is a key concept in software design that ensures each function or module in your code has one, and only one, reason to change. For students learning R, this means breaking down your code into smaller, well-defined functions where each function does one specific task. This makes your code easier to understand, test, and maintain [@noauthor_single-responsibility_nodate].

For example, instead of writing one long script that loads data, cleans it, and plots it, you can write separate functions for each task:
- `load_data()` handles loading the data.
- `clean_data()` takes care of data cleaning.
- `plot_data()` is responsible for plotting.

By adhering to SRP, you reduce the chance of introducing bugs when modifying or extending your code. If the way data is loaded changes, you only need to adjust `load_data()` without worrying about unintended side effects on `clean_data()` or `plot_data()`.

:::

#### **Example: Creating in-script custom functions** {.unnumbered}  
```r
# Custom function to calculate mean
calculate_mean <- function(data) {
  mean(data, na.rm = TRUE)
}

# Usage
numbers <- c(1, 2, 3, NA, 5)
calculate_mean(numbers)
```

#### **Example: Wrapping messy code into clear functions** {.unnumbered}  
**Messy Code Example:**
```{r, eval=FALSE}
#| eval: false
# Messy and hard to follow
data <- read.csv("data.csv")
data$cleaned <- na.omit(data$column)
data$scaled <- (data$cleaned - mean(data$cleaned)) / sd(data$cleaned)
hist(data$scaled)
```

**Wrapped in functions clearly defined:**
```{r, eval=FALSE}
#| eval: false
# Function to load data
load_data <- function(filepath) {
  read.csv(filepath)
}

# Function to clean data
clean_data <- function(data, column) {
  na.omit(data[[column]])
}

# Function to scale data
scale_data <- function(data) {
  (data - mean(data)) / sd(data)
}

# Function to plot histogram
plot_histogram <- function(data) {
  hist(data)
}

# Main execution sequence
main <- function() {
  raw_data <- load_data("data.csv")
  cleaned_data <- clean_data(raw_data, "column")
  scaled_data <- scale_data(cleaned_data)
  plot_histogram(scaled_data)
}

# Run the main function
main()
```

By organizing the operations into clear, single-responsibility functions, the code becomes more readable, maintainable, and easier to debug.

#### **Example: Creating and importing custom R scripts** {.unnumbered}  
1. **Creating a script:** Save the following function in a file named `utility_functions.R`.
   ```{r, eval=FALSE}
   #| eval: false
   # utility_functions.R
   calculate_sum <- function(data) {
     sum(data, na.rm = TRUE)
   }
   ```
2. **Importing the script:**
   ```{r, eval=FALSE}
   #| eval: false
   source("utility_functions.R") # loads all functions defined inside the script
   numbers <- c(1, 2, 3, NA, 5)
   calculate_sum(numbers)
   ```

### Code Structuring

**Structuring a data science project**  
A well-organized project structure separates code, data, and outputs, which facilitates efficient project management.

#### **Example: Setting up a basic project structure in R and RStudio** {.unnumbered}   
1. **Folder Structure:**
   ```
   my_project/  
   ├── data/  
   │   └── raw_data.csv  
   ├── scripts/  
   │   ├── 01_load_data.R  
   │   └── 02_analyse_data.R  
   │   └── 03_visualise_data.R  
   ├── outputs/  
   │   └── analysis_results.csv  
   └── workflow.R  
   └── my_project.Rproj  
   ```
   
2. **Script Example:**  
   - `01_load_data.R`
     ```{r, eval=FALSE}
     #| eval: false
     load_data <- function(file_name, dir = "data", save_rds = FALSE) {
       file_path <- paste(dir, file_name, sep = "/")
       # load raw data
       raw_data <- read.csv(paste(file_path, "csv", sep = "."))
       if (save_rds) {
         # save a copy as a R dataset (.rds)
         saveRDS(raw_data, file = paste(file_path, "rds", sep = "."))
       }
     }
     ```

   - `02_analyse_data.R`
     ```{r, eval=FALSE}
     #| eval: false
     analyze_data <- function() {
       summary_stats <- summary(raw_data)
       print(summary_stats)
       # Save the results to an output file
       write.csv(summary_stats, "outputs/analysis_results.csv")
     }
     ```

   - `03_visualise_data.R`
     ```{r, eval=FALSE}
     #| eval: false
     visualise_data <- function(dataset, plot_name, dir = "outputs", width = 480, height = 480) {
       file_path <- paste(dir, plot_name, sep = "/")
       file_name <- paste(file_path, "png", sep = ".")
       png(file_name, width = 480, height = 480)
       pairs(dataset) # matrix of scatterplots
       dev.off()
     }
     ```
     
   - `workflow.R`
     ```{r, eval=FALSE}
     source("01_load_data.R")
     source("02_analyze_data.R")
     
     dt <- load_data("raw_data")
     
     analyze_data(dt)
     
     visualise_data(dt, "Variables overview", width = 560, height = 560)
     ```

This structure ensures clarity, with each component of the project clearly demarcated, promoting better workflow and collaboration.

::: {.callout-note collapse="true"}
#### See also {.unnumbered}

- @grolemund_welcome_nodate  
- @gillespie_efficient_nodate  
- @noauthor_welcome_nodate  

:::

## Writing Clean and Readable Code

* **Naming Conventions**  
  * Using meaningful and consistent names for variables, functions, and files.  
  * Example: Best practices in naming conventions in R ([tidyverse style guide](https://style.tidyverse.org/index.html)).  
* **Commenting and Documentation**  
  * Importance of comments and inline documentation.  
  * Example: Writing using `roxygen2` in R for documenting functions.  
* **Avoiding Magic Numbers and Hardcoding**  
  * Use of constants and configuration files.  
  * Example: Using constants in R.

## Writing Efficient and Scalable Code

* **Vectorization**  
  * Avoiding loops by using vectorized operations for efficiency.  
  * Example: Implementing vectorized operations in R (base R, `dplyr`).  
* **Memory Management**  
  * Managing memory usage and avoiding memory leaks.  
  * Example: Best practices for handling large datasets in R (using `data.table`).

## (EXTRA)Testing and Validation

* **Writing Unit Tests**  
  * Importance of testing: ensuring code correctness.  
  * Example: Writing basic unit tests in Python (`unittest` or `pytest`) and R (`testthat`).  
* **Data Validation**  
  * Validating data inputs and outputs, ensuring data integrity.  
  * Example: Implementing data validation checks in data processing scripts.

## (EXTRA)Error Handling and Debugging

* **Error Handling Techniques**  
  * Using tryCatch in R.  
  * Writing meaningful error messages.   
  * Example: Implementing error handling in a data processing script.  
* **Debugging Tools**  
  * Introduction to debugging tools: `browser` in R.  
  * Example: Walkthrough of a debugging session in R.

## (EXTRA)Code Reusability and Sharing

* **Creating Reusable Code**  
  * Writing functions and libraries for reuse across projects.  
  * Example: Creating a simple R package.  
* **Sharing Code**  
  * Sharing code with others: publishing packages, sharing notebooks.  
  * Example: Publishing an R package on CRAN/GitHub.

::: {.callout-note icon=false}
## Hands-on Practice {.unnumbered}

* **Refactoring Code (30min)**  
  * First attempt: Refactoring a sample script to follow best practices (clean code, modularity, documentation).  
  * Second attempt: try using a Large Language Model (LLM) to refactor.  
* **Collaborative Exercise (40min)**  
  * Simulating a collaborative workflow with Git: making and reviewing pull requests.  
  * Groups of two or three  
  * Re-use one of the repositories created in GitHub (Session 2\) and populated by R code and output files (Session 3).  
  * Mutual reviews and change suggestions.  
  * Discussion, accepting/rejecting changes, and merge decision  
* **Open discussion (10min)**  
  * Addressing common challenges in applying best practices to real-world projects.

:::
